# Flight Insight
##### A Real-Time Flight Data Engineering Pipeline
Collect and display history of flight fares using the SkyScanner API

An **end-to-end data engineering project**.

---

### ðŸŽ¯ Project Goal (High Level)
**Build a Data Pipeline to Collect, Store, Process, and Visualize Real-Time Flight Data**

You will:
- Use modern, production-ready tools
- Create a repeatable, automated data pipeline
- Include monitoring, testing, and documentation
- Deliver a mini dashboard or API

---



### ðŸ” Use Case:
Collect global flight data (e.g. departures, arrivals, routes, delays), process it, and store it for trend analysis, alerts (like abnormal delays), or dashboards.

---

## ðŸ§± Tech Stack 

| Layer              | Tools/Tech                                      |
|-------------------|-------------------------------------------------|
| **Ingestion**      | Python, Requests, Airflow (Scheduler)           |
| **Orchestration**  | **Apache Airflow** (DAGs to automate ETL)       |
| **Storage**        | **PostgreSQL** (raw + cleaned data)             |
| **Processing**     | **dbt** (for SQL-based transformation)          |
| **Containerization**| **Docker** (run Airflow, PostgreSQL, etc.)     |
| **Monitoring**     | **Airflow UI**, **logging**, optional: Prometheus/Grafana |
| **Testing**        | Pytest + dbt tests                              |
| **Visualization**  | Streamlit or simple Flask dashboard             |
| **CI/CD (Bonus)**  | GitHub Actions                                  |
| **Infra (Bonus)**  | Terraform (if deploying on cloud)               |

---

## ðŸ—‚ï¸ Project Structure
```
flight_insight/
â”œâ”€â”€ dags/                   â† Airflow DAGs
â”œâ”€â”€ data/                   â† Local storage (if any)
â”œâ”€â”€ dbt/                    â† dbt models for transformation
â”œâ”€â”€ scripts/                â† Custom Python scripts
â”‚   â””â”€â”€ extract_flight_data.py
â”œâ”€â”€ docker/                 â† Docker configs
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ airflow/                â† Airflow-specific config (plugins, etc.)
â”œâ”€â”€ notebooks/              â† EDA, quick queries
â”œâ”€â”€ tests/                  â† Unit and integration tests
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

---

## ðŸ“ˆ Possible Features
### ðŸ”¹ Basic MVP
- Connect to aviation-edge API (e.g., departures, delays)
- Store raw data in PostgreSQL
- Schedule ingestion daily/hourly using Airflow
- Transform data using dbt (normalize, calculate delay stats)
- Dashboard to view delay trends per airport

### ðŸ”¹ Advanced Add-Ons
- Deduplicate and validate using dbt tests
- Detect anomalies (e.g. delay spike) using a basic ML model or SQL rule
- Streamlit dashboard showing top delayed routes, airlines, etc.
- Alerts (Slack/email) on specific triggers (e.g. >3hr delay)
- Archive old data to S3 (mock or real)
- Expose cleaned data via REST API (Flask/FastAPI)

---

## âœ… This Project Shows Off:
- Modern ETL design (modular, scalable)
- Hands-on with orchestration (Airflow)
- Real-world data processing (messy API data)
- Writing clean, testable Python code
- Deployment and automation skills (Docker, Airflow)
- Data modeling and transformation (dbt)
- Optional: basic visualization (not just backend)

---

